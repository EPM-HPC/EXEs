
Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_80
code version = [7,1]
producer = <unknown>
host = linux
compile_size = 64bit
compressed








.version 7.1
.target sm_80
.address_size 64


.func (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
.param .b64 __internal_trig_reduction_slowpathd_param_0,
.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func (.param .b64 func_retval0) __internal_accurate_pow
(
.param .b64 __internal_accurate_pow_param_0
)
;



.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .entry _Z17find_index_kernelPdS_S_S_S_S_S_i(
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_0,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_1,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_2,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_3,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_4,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_5,
.param .u64 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_6,
.param .u32 _Z17find_index_kernelPdS_S_S_S_S_S_i_param_7
)
{
.reg .pred %p<6>;
.reg .b32 %r<16>;
.reg .f64 %fd<5>;
.reg .b64 %rd<23>;


ld.param.u64 %rd2, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_0];
ld.param.u64 %rd3, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_1];
ld.param.u64 %rd4, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_2];
ld.param.u64 %rd5, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_3];
ld.param.u64 %rd6, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_4];
ld.param.u64 %rd7, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_5];
ld.param.u32 %r5, [_Z17find_index_kernelPdS_S_S_S_S_S_i_param_7];
mov.u32 %r6, %ntid.x;
mov.u32 %r7, %ctaid.x;
mov.u32 %r8, %tid.x;
mad.lo.s32 %r1, %r6, %r7, %r8;
setp.ge.s32	%p1, %r1, %r5;
@%p1 bra BB0_7;

mov.u32 %r9, -1;
setp.lt.s32	%p2, %r5, 1;
@%p2 bra BB0_5;

cvta.to.global.u64 %rd8, %rd5;
cvta.to.global.u64 %rd1, %rd4;
mul.wide.s32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
ld.global.f64 %fd1, [%rd10];
mov.u32 %r15, 0;

BB0_3:
mul.wide.s32 %rd11, %r15, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd2, [%rd12];
add.s32 %r3, %r15, 1;
setp.ge.f64	%p3, %fd2, %fd1;
@%p3 bra BB0_6;

setp.lt.s32	%p4, %r3, %r5;
mov.u32 %r15, %r3;
@%p4 bra BB0_3;

BB0_5:
mov.u32 %r15, %r9;

BB0_6:
cvta.to.global.u64 %rd13, %rd7;
cvta.to.global.u64 %rd14, %rd3;
cvta.to.global.u64 %rd15, %rd6;
cvta.to.global.u64 %rd16, %rd2;
add.s32 %r12, %r5, -1;
setp.eq.s32	%p5, %r15, -1;
selp.b32	%r13, %r12, %r15, %p5;
mul.wide.s32 %rd17, %r13, 8;
add.s64 %rd18, %rd16, %rd17;
ld.global.f64 %fd3, [%rd18];
mul.wide.s32 %rd19, %r1, 8;
add.s64 %rd20, %rd15, %rd19;
st.global.f64 [%rd20], %fd3;
add.s64 %rd21, %rd14, %rd17;
ld.global.f64 %fd4, [%rd21];
add.s64 %rd22, %rd13, %rd19;
st.global.f64 [%rd22], %fd4;

BB0_7:
bar.sync 0;
ret;
}


.visible .entry _Z24normalize_weights_kernelPdiS_S_S_Pi(
.param .u64 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_0,
.param .u32 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_1,
.param .u64 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_2,
.param .u64 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_3,
.param .u64 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_4,
.param .u64 _Z24normalize_weights_kernelPdiS_S_S_Pi_param_5
)
{
.reg .pred %p<12>;
.reg .b32 %r<31>;
.reg .f64 %fd<37>;
.reg .b64 %rd<28>;

	.shared .align 8 .f64 _ZZ24normalize_weights_kernelPdiS_S_S_PiE2u1;

	.shared .align 8 .f64 _ZZ24normalize_weights_kernelPdiS_S_S_PiE10sumWeights;

ld.param.u64 %rd10, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_0];
ld.param.u32 %r11, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_1];
ld.param.u64 %rd8, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_2];
ld.param.u64 %rd11, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_3];
ld.param.u64 %rd12, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_4];
ld.param.u64 %rd9, [_Z24normalize_weights_kernelPdiS_S_S_Pi_param_5];
cvta.to.global.u64 %rd1, %rd12;
cvta.to.global.u64 %rd2, %rd11;
cvta.to.global.u64 %rd3, %rd10;
mov.u32 %r12, %ntid.x;
mov.u32 %r13, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r2, %r12, %r13, %r1;
setp.ne.s32	%p3, %r1, 0;
@%p3 bra BB1_2;

cvta.to.global.u64 %rd13, %rd8;
ld.global.f64 %fd6, [%rd13];
st.shared.f64 [_ZZ24normalize_weights_kernelPdiS_S_S_PiE10sumWeights], %fd6;

BB1_2:
bar.sync 0;
setp.ge.s32	%p4, %r2, %r11;
@%p4 bra BB1_4;

mul.wide.s32 %rd14, %r2, 8;
add.s64 %rd15, %rd3, %rd14;
ld.shared.f64 %fd7, [_ZZ24normalize_weights_kernelPdiS_S_S_PiE10sumWeights];
ld.global.f64 %fd8, [%rd15];
div.rn.f64 %fd9, %fd8, %fd7;
st.global.f64 [%rd15], %fd9;

BB1_4:
bar.sync 0;
setp.ne.s32	%p5, %r2, 0;
@%p5 bra BB1_16;

ld.global.f64 %fd1, [%rd3];
st.global.f64 [%rd2], %fd1;
setp.lt.s32	%p6, %r11, 2;
@%p6 bra BB1_15;

add.s32 %r3, %r11, -1;
and.b32 %r17, %r3, 3;
mov.u32 %r27, 1;
setp.eq.s32	%p7, %r17, 0;
@%p7 bra BB1_12;

setp.eq.s32	%p8, %r17, 1;
@%p8 bra BB1_11;

setp.eq.s32	%p9, %r17, 2;
@%p9 bra BB1_10;

ld.global.f64 %fd10, [%rd3+8];
add.f64 %fd1, %fd10, %fd1;
st.global.f64 [%rd2+8], %fd1;
mov.u32 %r27, 2;

BB1_10:
mul.wide.s32 %rd16, %r27, 8;
add.s64 %rd17, %rd3, %rd16;
ld.global.f64 %fd11, [%rd17];
add.s64 %rd18, %rd2, %rd16;
add.f64 %fd1, %fd11, %fd1;
st.global.f64 [%rd18], %fd1;
add.s32 %r27, %r27, 1;

BB1_11:
mul.wide.s32 %rd19, %r27, 8;
add.s64 %rd20, %rd3, %rd19;
ld.global.f64 %fd12, [%rd20];
add.f64 %fd13, %fd12, %fd1;
add.s64 %rd21, %rd2, %rd19;
st.global.f64 [%rd21], %fd13;
add.s32 %r27, %r27, 1;

BB1_12:
setp.lt.u32	%p10, %r3, 4;
@%p10 bra BB1_15;

mul.wide.s32 %rd27, %r27, 8;

BB1_14:
add.s64 %rd22, %rd3, %rd27;
add.s64 %rd23, %rd2, %rd27;
ld.global.f64 %fd14, [%rd23+-8];
ld.global.f64 %fd15, [%rd22];
add.f64 %fd16, %fd15, %fd14;
st.global.f64 [%rd23], %fd16;
ld.global.f64 %fd17, [%rd22+8];
add.f64 %fd18, %fd17, %fd16;
st.global.f64 [%rd23+8], %fd18;
ld.global.f64 %fd19, [%rd22+16];
add.f64 %fd20, %fd19, %fd18;
st.global.f64 [%rd23+16], %fd20;
ld.global.f64 %fd21, [%rd22+24];
add.f64 %fd22, %fd21, %fd20;
st.global.f64 [%rd23+24], %fd22;
add.s64 %rd27, %rd27, 32;
add.s32 %r27, %r27, 4;
setp.lt.s32	%p11, %r27, %r11;
@%p11 bra BB1_14;

BB1_15:
cvta.to.global.u64 %rd24, %rd9;
cvt.rn.f64.s32	%fd23, %r11;
rcp.rn.f64 %fd24, %fd23;
ld.global.u32 %r19, [%rd24];
mad.lo.s32 %r20, %r19, 1103515245, 12345;
mul.hi.s32 %r21, %r20, 1073741825;
shr.u32 %r22, %r21, 31;
shr.s32 %r23, %r21, 29;
add.s32 %r24, %r23, %r22;
mul.lo.s32 %r25, %r24, 2147483647;
sub.s32 %r26, %r20, %r25;
st.global.u32 [%rd24], %r26;
cvt.rn.f64.s32	%fd25, %r26;
div.rn.f64 %fd26, %fd25, 0d41DFFFFFFFC00000;
abs.f64 %fd27, %fd26;
mul.f64 %fd28, %fd24, %fd27;
st.global.f64 [%rd1], %fd28;

BB1_16:
setp.eq.s32	%p1, %r1, 0;
bar.sync 0;
@!%p1 bra BB1_18;
bra.uni BB1_17;

BB1_17:
ld.global.f64 %fd29, [%rd1];
st.shared.f64 [_ZZ24normalize_weights_kernelPdiS_S_S_PiE2u1], %fd29;

BB1_18:
setp.lt.s32	%p2, %r2, %r11;
bar.sync 0;
@!%p2 bra BB1_20;
bra.uni BB1_19;

BB1_19:
ld.shared.f64 %fd30, [_ZZ24normalize_weights_kernelPdiS_S_S_PiE2u1];
cvt.rn.f64.s32	%fd31, %r11;
cvt.rn.f64.s32	%fd32, %r2;
div.rn.f64 %fd33, %fd32, %fd31;
add.f64 %fd34, %fd30, %fd33;
mul.wide.s32 %rd25, %r2, 8;
add.s64 %rd26, %rd1, %rd25;
st.global.f64 [%rd26], %fd34;

BB1_20:
ret;
}


.visible .entry _Z10sum_kernelPdi(
.param .u64 _Z10sum_kernelPdi_param_0,
.param .u32 _Z10sum_kernelPdi_param_1
)
{
.reg .pred %p<8>;
.reg .b32 %r<24>;
.reg .f64 %fd<32>;
.reg .b64 %rd<12>;


ld.param.u64 %rd5, [_Z10sum_kernelPdi_param_0];
ld.param.u32 %r9, [_Z10sum_kernelPdi_param_1];
cvta.to.global.u64 %rd1, %rd5;
mov.u32 %r10, %ntid.x;
mov.u32 %r11, %ctaid.x;
mul.lo.s32 %r12, %r10, %r11;
mov.u32 %r13, %tid.x;
neg.s32 %r14, %r13;
setp.ne.s32	%p1, %r12, %r14;
@%p1 bra BB2_12;

cvt.rn.f64.s32	%fd11, %r9;
mul.f64 %fd12, %fd11, 0d3F60000000000000;
cvt.rpi.f64.f64	%fd13, %fd12;
cvt.rzi.s32.f64	%r1, %fd13;
mov.f64 %fd31, 0d0000000000000000;
setp.lt.s32	%p2, %r1, 1;
@%p2 bra BB2_11;

and.b32 %r18, %r1, 3;
mov.u32 %r22, 0;
mov.f64 %fd31, 0d0000000000000000;
setp.eq.s32	%p3, %r18, 0;
@%p3 bra BB2_8;

setp.eq.s32	%p4, %r18, 1;
@%p4 bra BB2_7;

setp.eq.s32	%p5, %r18, 2;
@%p5 bra BB2_6;

ld.global.f64 %fd17, [%rd1];
add.f64 %fd31, %fd17, 0d0000000000000000;
mov.u32 %r22, 1;

BB2_6:
mul.wide.u32 %rd6, %r22, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd18, [%rd7];
add.f64 %fd31, %fd31, %fd18;
add.s32 %r22, %r22, 1;

BB2_7:
mul.wide.s32 %rd8, %r22, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd19, [%rd9];
add.f64 %fd31, %fd31, %fd19;
add.s32 %r22, %r22, 1;

BB2_8:
setp.lt.u32	%p6, %r1, 4;
@%p6 bra BB2_11;

mul.wide.s32 %rd10, %r22, 8;
add.s64 %rd11, %rd1, %rd10;

BB2_10:
ld.global.f64 %fd20, [%rd11];
add.f64 %fd21, %fd31, %fd20;
ld.global.f64 %fd22, [%rd11+8];
add.f64 %fd23, %fd21, %fd22;
ld.global.f64 %fd24, [%rd11+16];
add.f64 %fd25, %fd23, %fd24;
ld.global.f64 %fd26, [%rd11+24];
add.f64 %fd31, %fd25, %fd26;
add.s64 %rd11, %rd11, 32;
add.s32 %r22, %r22, 4;
setp.lt.s32	%p7, %r22, %r1;
@%p7 bra BB2_10;

BB2_11:
st.global.f64 [%rd1], %fd31;

BB2_12:
ret;
}


.visible .entry _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S_(
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_0,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_1,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_2,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_3,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_4,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_5,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_6,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_7,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_8,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_9,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_10,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_11,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_12,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_13,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_14,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_15,
.param .u32 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_16,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_17,
.param .u64 _Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_18
)
{
.local .align 4 .b8 __local_depot3[8];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<85>;
.reg .f32 %f<5>;
.reg .b32 %r<309>;
.reg .f64 %fd<381>;
.reg .b64 %rd<87>;

	.shared .align 8 .b8 _ZZ17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S_E6buffer[4096];

mov.u64 %SPL, __local_depot3;
cvta.local.u64 %SP, %SPL;
ld.param.u64 %rd23, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_0];
ld.param.u64 %rd24, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_1];
ld.param.u64 %rd17, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_2];
ld.param.u64 %rd18, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_3];
ld.param.u64 %rd25, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_5];
ld.param.u64 %rd26, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_6];
ld.param.u64 %rd27, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_10];
ld.param.u32 %r61, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_11];
ld.param.u32 %r62, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_12];
ld.param.u32 %r63, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_13];
ld.param.u32 %r64, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_14];
ld.param.u32 %r65, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_15];
ld.param.u32 %r66, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_16];
ld.param.u64 %rd21, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_17];
cvta.to.global.u64 %rd1, %rd26;
cvta.to.global.u64 %rd2, %rd25;
add.u64 %rd29, %SP, 4;
add.u64 %rd4, %SPL, 4;
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r1, %r2, %r3;
cvta.to.global.u64 %rd30, %rd23;
mul.wide.s32 %rd31, %r4, 8;
add.s64 %rd5, %rd30, %rd31;
cvta.to.global.u64 %rd32, %rd24;
add.s64 %rd6, %rd32, %rd31;
cvta.to.global.u64 %rd33, %rd27;
add.s64 %rd7, %rd33, %rd31;
setp.ge.s32	%p6, %r4, %r61;
@%p6 bra BB3_34;

cvta.to.global.u64 %rd34, %rd21;
cvta.to.global.u64 %rd35, %rd17;
add.s64 %rd37, %rd35, %rd31;
ld.global.f64 %fd79, [%rd37];
st.global.f64 [%rd5], %fd79;
cvta.to.global.u64 %rd38, %rd18;
add.s64 %rd39, %rd38, %rd31;
ld.global.f64 %fd80, [%rd39];
st.global.f64 [%rd6], %fd80;
cvt.rn.f64.s32	%fd81, %r61;
rcp.rn.f64 %fd82, %fd81;
st.global.f64 [%rd7], %fd82;
ld.global.f64 %fd1, [%rd5];
mul.wide.s32 %rd40, %r4, 4;
add.s64 %rd8, %rd34, %rd40;
ld.global.u32 %r67, [%rd8];
mad.lo.s32 %r68, %r67, 1103515245, 12345;
mul.hi.s32 %r69, %r68, 1073741825;
shr.u32 %r70, %r69, 31;
shr.s32 %r71, %r69, 29;
add.s32 %r72, %r71, %r70;
mul.lo.s32 %r73, %r72, 2147483647;
sub.s32 %r74, %r68, %r73;
cvt.rn.f64.s32	%fd83, %r74;
div.rn.f64 %fd84, %fd83, 0d41DFFFFFFFC00000;
abs.f64 %fd362, %fd84;
mad.lo.s32 %r75, %r74, 1103515245, 12345;
mul.hi.s32 %r76, %r75, 1073741825;
shr.u32 %r77, %r76, 31;
shr.s32 %r78, %r76, 29;
add.s32 %r79, %r78, %r77;
mul.lo.s32 %r80, %r79, 2147483647;
sub.s32 %r81, %r75, %r80;
st.global.u32 [%rd8], %r81;
cvt.rn.f64.s32	%fd85, %r81;
div.rn.f64 %fd86, %fd85, 0d41DFFFFFFFC00000;
abs.f64 %fd87, %fd86;
mul.f64 %fd358, %fd87, 0d401921FB54442D18;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r82}, %fd358;
}
and.b32 %r83, %r82, 2147483647;
setp.ne.s32	%p7, %r83, 2146435072;
@%p7 bra BB3_4;

{
.reg .b32 %temp; 
mov.b64 {%r84, %temp}, %fd358;
}
setp.ne.s32	%p8, %r84, 0;
@%p8 bra BB3_4;

mov.f64 %fd88, 0d0000000000000000;
mul.rn.f64 %fd358, %fd358, %fd88;

BB3_4:
mul.f64 %fd89, %fd358, 0d3FE45F306DC9C883;
cvt.rni.s32.f64	%r292, %fd89;
st.local.u32 [%rd4], %r292;
cvt.rn.f64.s32	%fd90, %r292;
neg.f64 %fd91, %fd90;
mov.f64 %fd92, 0d3FF921FB54442D18;
fma.rn.f64 %fd93, %fd91, %fd92, %fd358;
mov.f64 %fd94, 0d3C91A62633145C00;
fma.rn.f64 %fd95, %fd91, %fd94, %fd93;
mov.f64 %fd96, 0d397B839A252049C0;
fma.rn.f64 %fd359, %fd91, %fd96, %fd95;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r85}, %fd358;
}
and.b32 %r86, %r85, 2145386496;
setp.lt.u32	%p9, %r86, 1105199104;
@%p9 bra BB3_6;


	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd358;
.param .b64 param1;
st.param.b64	[param1+0], %rd29;
.param .b64 retval0;
call.uni (retval0), 
__internal_trig_reduction_slowpathd, 
(
param0, 
param1
);
ld.param.f64	%fd359, [retval0+0];


	}
	ld.local.u32 %r292, [%rd4];

BB3_6:
add.s32 %r8, %r292, 1;
and.b32 %r87, %r8, 1;
shl.b32 %r88, %r87, 3;
setp.eq.b32	%p10, %r87, 1;
selp.f64	%fd97, 0dBDA8FF8320FD8164, 0d3DE5DB65F9785EBA, %p10;
mul.wide.u32 %rd42, %r88, 8;
mov.u64 %rd43, __cudart_sin_cos_coeffs;
add.s64 %rd44, %rd42, %rd43;
ld.global.f64 %fd98, [%rd44+8];
mul.rn.f64 %fd9, %fd359, %fd359;
fma.rn.f64 %fd99, %fd97, %fd9, %fd98;
ld.global.f64 %fd100, [%rd44+16];
fma.rn.f64 %fd101, %fd99, %fd9, %fd100;
ld.global.f64 %fd102, [%rd44+24];
fma.rn.f64 %fd103, %fd101, %fd9, %fd102;
ld.global.f64 %fd104, [%rd44+32];
fma.rn.f64 %fd105, %fd103, %fd9, %fd104;
ld.global.f64 %fd106, [%rd44+40];
fma.rn.f64 %fd107, %fd105, %fd9, %fd106;
ld.global.f64 %fd108, [%rd44+48];
fma.rn.f64 %fd10, %fd107, %fd9, %fd108;
fma.rn.f64 %fd360, %fd10, %fd359, %fd359;
setp.eq.s32	%p11, %r87, 0;
@%p11 bra BB3_8;

mov.f64 %fd109, 0d3FF0000000000000;
fma.rn.f64 %fd360, %fd10, %fd9, %fd109;

BB3_8:
and.b32 %r89, %r8, 2;
setp.eq.s32	%p12, %r89, 0;
@%p12 bra BB3_10;

mov.f64 %fd110, 0d0000000000000000;
mov.f64 %fd111, 0dBFF0000000000000;
fma.rn.f64 %fd360, %fd360, %fd111, %fd110;

BB3_10:
{
.reg .b32 %temp; 
mov.b64 {%r294, %temp}, %fd362;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r293}, %fd362;
}
mov.u32 %r295, -1023;
setp.gt.s32	%p13, %r293, 1048575;
@%p13 bra BB3_12;

mul.f64 %fd362, %fd362, 0d4350000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r293}, %fd362;
}
{
.reg .b32 %temp; 
mov.b64 {%r294, %temp}, %fd362;
}
mov.u32 %r295, -1077;

BB3_12:
add.s32 %r92, %r293, -1;
setp.lt.u32	%p14, %r92, 2146435071;
@%p14 bra BB3_14;
bra.uni BB3_13;

BB3_14:
shr.u32 %r94, %r293, 20;
add.s32 %r296, %r295, %r94;
and.b32 %r95, %r293, -2146435073;
or.b32 %r96, %r95, 1072693248;
mov.b64 %fd363, {%r294, %r96};
setp.lt.s32	%p16, %r96, 1073127583;
@%p16 bra BB3_16;

{
.reg .b32 %temp; 
mov.b64 {%r97, %temp}, %fd363;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r98}, %fd363;
}
add.s32 %r99, %r98, -1048576;
mov.b64 %fd363, {%r97, %r99};
add.s32 %r296, %r296, 1;

BB3_16:
add.f64 %fd114, %fd363, 0d3FF0000000000000;
rcp.approx.ftz.f64 %fd115, %fd114;
neg.f64 %fd116, %fd114;
mov.f64 %fd117, 0d3FF0000000000000;
fma.rn.f64 %fd118, %fd116, %fd115, %fd117;
fma.rn.f64 %fd119, %fd118, %fd118, %fd118;
fma.rn.f64 %fd120, %fd119, %fd115, %fd115;
add.f64 %fd121, %fd363, 0dBFF0000000000000;
mul.f64 %fd122, %fd121, %fd120;
fma.rn.f64 %fd123, %fd121, %fd120, %fd122;
mul.f64 %fd124, %fd123, %fd123;
mov.f64 %fd125, 0d3ED0EE258B7A8B04;
mov.f64 %fd126, 0d3EB1380B3AE80F1E;
fma.rn.f64 %fd127, %fd126, %fd124, %fd125;
mov.f64 %fd128, 0d3EF3B2669F02676F;
fma.rn.f64 %fd129, %fd127, %fd124, %fd128;
mov.f64 %fd130, 0d3F1745CBA9AB0956;
fma.rn.f64 %fd131, %fd129, %fd124, %fd130;
mov.f64 %fd132, 0d3F3C71C72D1B5154;
fma.rn.f64 %fd133, %fd131, %fd124, %fd132;
mov.f64 %fd134, 0d3F624924923BE72D;
fma.rn.f64 %fd135, %fd133, %fd124, %fd134;
mov.f64 %fd136, 0d3F8999999999A3C4;
fma.rn.f64 %fd137, %fd135, %fd124, %fd136;
mov.f64 %fd138, 0d3FB5555555555554;
fma.rn.f64 %fd139, %fd137, %fd124, %fd138;
sub.f64 %fd140, %fd121, %fd123;
add.f64 %fd141, %fd140, %fd140;
neg.f64 %fd142, %fd123;
fma.rn.f64 %fd143, %fd142, %fd121, %fd141;
mul.f64 %fd144, %fd120, %fd143;
mul.f64 %fd145, %fd124, %fd139;
fma.rn.f64 %fd146, %fd145, %fd123, %fd144;
xor.b32 %r100, %r296, -2147483648;
mov.u32 %r101, -2147483648;
mov.u32 %r102, 1127219200;
mov.b64 %fd147, {%r100, %r102};
mov.b64 %fd148, {%r101, %r102};
sub.f64 %fd149, %fd147, %fd148;
mov.f64 %fd150, 0d3FE62E42FEFA39EF;
fma.rn.f64 %fd151, %fd149, %fd150, %fd123;
neg.f64 %fd152, %fd149;
fma.rn.f64 %fd153, %fd152, %fd150, %fd151;
sub.f64 %fd154, %fd153, %fd123;
sub.f64 %fd155, %fd146, %fd154;
mov.f64 %fd156, 0d3C7ABC9E3B39803F;
fma.rn.f64 %fd157, %fd149, %fd156, %fd155;
add.f64 %fd364, %fd151, %fd157;
bra.uni BB3_17;

BB3_13:
mov.f64 %fd112, 0d7FF0000000000000;
fma.rn.f64 %fd113, %fd362, %fd112, %fd112;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r93}, %fd362;
}
mov.b32 %f2, %r93;
setp.eq.ftz.f32	%p15, %f2, 0f00000000;
selp.f64	%fd364, 0dFFF0000000000000, %fd113, %p15;

BB3_17:
mul.f64 %fd158, %fd364, 0dC000000000000000;
sqrt.rn.f64 %fd159, %fd158;
mul.f64 %fd160, %fd360, %fd159;
add.f64 %fd161, %fd1, 0d3FF0000000000000;
fma.rn.f64 %fd162, %fd160, 0d4014000000000000, %fd161;
st.global.f64 [%rd5], %fd162;
ld.global.f64 %fd24, [%rd6];
ld.global.u32 %r103, [%rd8];
mad.lo.s32 %r104, %r103, 1103515245, 12345;
mul.hi.s32 %r105, %r104, 1073741825;
shr.u32 %r106, %r105, 31;
shr.s32 %r107, %r105, 29;
add.s32 %r108, %r107, %r106;
mul.lo.s32 %r109, %r108, 2147483647;
sub.s32 %r110, %r104, %r109;
cvt.rn.f64.s32	%fd163, %r110;
div.rn.f64 %fd164, %fd163, 0d41DFFFFFFFC00000;
abs.f64 %fd369, %fd164;
mad.lo.s32 %r111, %r110, 1103515245, 12345;
mul.hi.s32 %r112, %r111, 1073741825;
shr.u32 %r113, %r112, 31;
shr.s32 %r114, %r112, 29;
add.s32 %r115, %r114, %r113;
mul.lo.s32 %r116, %r115, 2147483647;
sub.s32 %r117, %r111, %r116;
st.global.u32 [%rd8], %r117;
cvt.rn.f64.s32	%fd165, %r117;
div.rn.f64 %fd166, %fd165, 0d41DFFFFFFFC00000;
abs.f64 %fd167, %fd166;
mul.f64 %fd365, %fd167, 0d401921FB54442D18;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r118}, %fd365;
}
and.b32 %r119, %r118, 2147483647;
setp.ne.s32	%p17, %r119, 2146435072;
@%p17 bra BB3_20;

{
.reg .b32 %temp; 
mov.b64 {%r120, %temp}, %fd365;
}
setp.ne.s32	%p18, %r120, 0;
@%p18 bra BB3_20;

mov.f64 %fd168, 0d0000000000000000;
mul.rn.f64 %fd365, %fd365, %fd168;

BB3_20:
add.u64 %rd81, %SPL, 0;
mov.f64 %fd357, 0d397B839A252049C0;
mov.f64 %fd356, 0d3C91A62633145C00;
mov.f64 %fd355, 0d3FF921FB54442D18;
mul.f64 %fd169, %fd365, 0d3FE45F306DC9C883;
cvt.rni.s32.f64	%r297, %fd169;
st.local.u32 [%rd81], %r297;
cvt.rn.f64.s32	%fd170, %r297;
neg.f64 %fd171, %fd170;
fma.rn.f64 %fd173, %fd171, %fd355, %fd365;
fma.rn.f64 %fd175, %fd171, %fd356, %fd173;
fma.rn.f64 %fd366, %fd171, %fd357, %fd175;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r121}, %fd365;
}
and.b32 %r122, %r121, 2145386496;
setp.lt.u32	%p19, %r122, 1105199104;
@%p19 bra BB3_22;

add.u64 %rd83, %SPL, 0;
add.u64 %rd77, %SP, 0;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd365;
.param .b64 param1;
st.param.b64	[param1+0], %rd77;
.param .b64 retval0;
call.uni (retval0), 
__internal_trig_reduction_slowpathd, 
(
param0, 
param1
);
ld.param.f64	%fd366, [retval0+0];


	}
	ld.local.u32 %r297, [%rd83];

BB3_22:
mov.u64 %rd75, __cudart_sin_cos_coeffs;
add.s32 %r22, %r297, 1;
and.b32 %r123, %r22, 1;
shl.b32 %r124, %r123, 3;
setp.eq.b32	%p20, %r123, 1;
selp.f64	%fd177, 0dBDA8FF8320FD8164, 0d3DE5DB65F9785EBA, %p20;
mul.wide.u32 %rd46, %r124, 8;
add.s64 %rd48, %rd46, %rd75;
ld.global.f64 %fd178, [%rd48+8];
mul.rn.f64 %fd32, %fd366, %fd366;
fma.rn.f64 %fd179, %fd177, %fd32, %fd178;
ld.global.f64 %fd180, [%rd48+16];
fma.rn.f64 %fd181, %fd179, %fd32, %fd180;
ld.global.f64 %fd182, [%rd48+24];
fma.rn.f64 %fd183, %fd181, %fd32, %fd182;
ld.global.f64 %fd184, [%rd48+32];
fma.rn.f64 %fd185, %fd183, %fd32, %fd184;
ld.global.f64 %fd186, [%rd48+40];
fma.rn.f64 %fd187, %fd185, %fd32, %fd186;
ld.global.f64 %fd188, [%rd48+48];
fma.rn.f64 %fd33, %fd187, %fd32, %fd188;
fma.rn.f64 %fd367, %fd33, %fd366, %fd366;
setp.eq.s32	%p21, %r123, 0;
@%p21 bra BB3_24;

mov.f64 %fd189, 0d3FF0000000000000;
fma.rn.f64 %fd367, %fd33, %fd32, %fd189;

BB3_24:
and.b32 %r125, %r22, 2;
setp.eq.s32	%p22, %r125, 0;
@%p22 bra BB3_26;

mov.f64 %fd190, 0d0000000000000000;
mov.f64 %fd191, 0dBFF0000000000000;
fma.rn.f64 %fd367, %fd367, %fd191, %fd190;

BB3_26:
{
.reg .b32 %temp; 
mov.b64 {%r299, %temp}, %fd369;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r298}, %fd369;
}
mov.u32 %r300, -1023;
setp.gt.s32	%p23, %r298, 1048575;
@%p23 bra BB3_28;

mul.f64 %fd369, %fd369, 0d4350000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r298}, %fd369;
}
{
.reg .b32 %temp; 
mov.b64 {%r299, %temp}, %fd369;
}
mov.u32 %r300, -1077;

BB3_28:
add.s32 %r128, %r298, -1;
setp.lt.u32	%p24, %r128, 2146435071;
@%p24 bra BB3_30;
bra.uni BB3_29;

BB3_30:
shr.u32 %r130, %r298, 20;
add.s32 %r301, %r300, %r130;
and.b32 %r131, %r298, -2146435073;
or.b32 %r132, %r131, 1072693248;
mov.b64 %fd370, {%r299, %r132};
setp.lt.s32	%p26, %r132, 1073127583;
@%p26 bra BB3_32;

{
.reg .b32 %temp; 
mov.b64 {%r133, %temp}, %fd370;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r134}, %fd370;
}
add.s32 %r135, %r134, -1048576;
mov.b64 %fd370, {%r133, %r135};
add.s32 %r301, %r301, 1;

BB3_32:
add.f64 %fd194, %fd370, 0d3FF0000000000000;
rcp.approx.ftz.f64 %fd195, %fd194;
neg.f64 %fd196, %fd194;
mov.f64 %fd197, 0d3FF0000000000000;
fma.rn.f64 %fd198, %fd196, %fd195, %fd197;
fma.rn.f64 %fd199, %fd198, %fd198, %fd198;
fma.rn.f64 %fd200, %fd199, %fd195, %fd195;
add.f64 %fd201, %fd370, 0dBFF0000000000000;
mul.f64 %fd202, %fd201, %fd200;
fma.rn.f64 %fd203, %fd201, %fd200, %fd202;
mul.f64 %fd204, %fd203, %fd203;
mov.f64 %fd205, 0d3ED0EE258B7A8B04;
mov.f64 %fd206, 0d3EB1380B3AE80F1E;
fma.rn.f64 %fd207, %fd206, %fd204, %fd205;
mov.f64 %fd208, 0d3EF3B2669F02676F;
fma.rn.f64 %fd209, %fd207, %fd204, %fd208;
mov.f64 %fd210, 0d3F1745CBA9AB0956;
fma.rn.f64 %fd211, %fd209, %fd204, %fd210;
mov.f64 %fd212, 0d3F3C71C72D1B5154;
fma.rn.f64 %fd213, %fd211, %fd204, %fd212;
mov.f64 %fd214, 0d3F624924923BE72D;
fma.rn.f64 %fd215, %fd213, %fd204, %fd214;
mov.f64 %fd216, 0d3F8999999999A3C4;
fma.rn.f64 %fd217, %fd215, %fd204, %fd216;
mov.f64 %fd218, 0d3FB5555555555554;
fma.rn.f64 %fd219, %fd217, %fd204, %fd218;
sub.f64 %fd220, %fd201, %fd203;
add.f64 %fd221, %fd220, %fd220;
neg.f64 %fd222, %fd203;
fma.rn.f64 %fd223, %fd222, %fd201, %fd221;
mul.f64 %fd224, %fd200, %fd223;
mul.f64 %fd225, %fd204, %fd219;
fma.rn.f64 %fd226, %fd225, %fd203, %fd224;
xor.b32 %r136, %r301, -2147483648;
mov.u32 %r137, -2147483648;
mov.u32 %r138, 1127219200;
mov.b64 %fd227, {%r136, %r138};
mov.b64 %fd228, {%r137, %r138};
sub.f64 %fd229, %fd227, %fd228;
mov.f64 %fd230, 0d3FE62E42FEFA39EF;
fma.rn.f64 %fd231, %fd229, %fd230, %fd203;
neg.f64 %fd232, %fd229;
fma.rn.f64 %fd233, %fd232, %fd230, %fd231;
sub.f64 %fd234, %fd233, %fd203;
sub.f64 %fd235, %fd226, %fd234;
mov.f64 %fd236, 0d3C7ABC9E3B39803F;
fma.rn.f64 %fd237, %fd229, %fd236, %fd235;
add.f64 %fd371, %fd231, %fd237;
bra.uni BB3_33;

BB3_29:
mov.f64 %fd192, 0d7FF0000000000000;
fma.rn.f64 %fd193, %fd369, %fd192, %fd192;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r129}, %fd369;
}
mov.b32 %f3, %r129;
setp.eq.ftz.f32	%p25, %f3, 0f00000000;
selp.f64	%fd371, 0dFFF0000000000000, %fd193, %p25;

BB3_33:
mul.f64 %fd238, %fd371, 0dC000000000000000;
sqrt.rn.f64 %fd239, %fd238;
mul.f64 %fd240, %fd367, %fd239;
add.f64 %fd241, %fd24, 0dC000000000000000;
fma.rn.f64 %fd242, %fd240, 0d4000000000000000, %fd241;
st.global.f64 [%rd6], %fd242;

BB3_34:
ld.param.u32 %r285, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_11];
setp.lt.s32	%p1, %r4, %r285;
bar.sync 0;
@!%p1 bra BB3_86;
bra.uni BB3_35;

BB3_35:
mov.f64 %fd379, 0d0000000000000000;
setp.lt.s32	%p27, %r62, 1;
@%p27 bra BB3_82;

mul.lo.s32 %r33, %r4, %r62;
and.b32 %r142, %r62, 3;
mov.u32 %r302, 0;
setp.eq.s32	%p28, %r142, 0;
@%p28 bra BB3_42;

setp.eq.s32	%p29, %r142, 1;
@%p29 bra BB3_41;

setp.eq.s32	%p30, %r142, 2;
@%p30 bra BB3_40;

ld.global.f64 %fd244, [%rd5];
cvt.rzi.s32.f64	%r144, %fd244;
cvt.rn.f64.s32	%fd245, %r144;
ld.global.u32 %r145, [%rd1+4];
cvt.rn.f64.s32	%fd246, %r145;
add.f64 %fd247, %fd245, %fd246;
cvt.rzi.s32.f64	%r146, %fd247;
ld.global.f64 %fd248, [%rd6];
cvt.rzi.s32.f64	%r147, %fd248;
cvt.rn.f64.s32	%fd249, %r147;
ld.global.u32 %r148, [%rd1];
cvt.rn.f64.s32	%fd250, %r148;
add.f64 %fd251, %fd249, %fd250;
cvt.rzi.s32.f64	%r149, %fd251;
mad.lo.s32 %r150, %r146, %r65, %r149;
mad.lo.s32 %r151, %r150, %r66, %r64;
abs.s32 %r152, %r151;
mul.wide.s32 %rd49, %r33, 4;
add.s64 %rd50, %rd2, %rd49;
setp.lt.s32	%p31, %r152, %r63;
selp.b32	%r153, %r152, 0, %p31;
st.global.u32 [%rd50], %r153;
mov.u32 %r302, 1;

BB3_40:
ld.global.f64 %fd252, [%rd5];
cvt.rzi.s32.f64	%r154, %fd252;
cvt.rn.f64.s32	%fd253, %r154;
shl.b32 %r155, %r302, 1;
add.s32 %r156, %r155, 1;
mul.wide.u32 %rd51, %r156, 4;
add.s64 %rd52, %rd1, %rd51;
ld.global.u32 %r157, [%rd52];
cvt.rn.f64.s32	%fd254, %r157;
add.f64 %fd255, %fd253, %fd254;
cvt.rzi.s32.f64	%r158, %fd255;
ld.global.f64 %fd256, [%rd6];
cvt.rzi.s32.f64	%r159, %fd256;
cvt.rn.f64.s32	%fd257, %r159;
mul.wide.u32 %rd53, %r155, 4;
add.s64 %rd54, %rd1, %rd53;
ld.global.u32 %r160, [%rd54];
cvt.rn.f64.s32	%fd258, %r160;
add.f64 %fd259, %fd257, %fd258;
cvt.rzi.s32.f64	%r161, %fd259;
mad.lo.s32 %r162, %r158, %r65, %r161;
mad.lo.s32 %r163, %r162, %r66, %r64;
abs.s32 %r164, %r163;
add.s32 %r165, %r302, %r33;
mul.wide.s32 %rd55, %r165, 4;
add.s64 %rd56, %rd2, %rd55;
setp.lt.s32	%p32, %r164, %r63;
selp.b32	%r166, %r164, 0, %p32;
st.global.u32 [%rd56], %r166;
add.s32 %r302, %r302, 1;

BB3_41:
ld.global.f64 %fd260, [%rd5];
cvt.rzi.s32.f64	%r167, %fd260;
cvt.rn.f64.s32	%fd261, %r167;
shl.b32 %r168, %r302, 1;
mul.wide.s32 %rd57, %r168, 4;
add.s64 %rd58, %rd1, %rd57;
ld.global.u32 %r169, [%rd58+4];
cvt.rn.f64.s32	%fd262, %r169;
add.f64 %fd263, %fd261, %fd262;
cvt.rzi.s32.f64	%r170, %fd263;
ld.global.f64 %fd264, [%rd6];
cvt.rzi.s32.f64	%r171, %fd264;
cvt.rn.f64.s32	%fd265, %r171;
ld.global.u32 %r172, [%rd58];
cvt.rn.f64.s32	%fd266, %r172;
add.f64 %fd267, %fd265, %fd266;
cvt.rzi.s32.f64	%r173, %fd267;
mad.lo.s32 %r174, %r170, %r65, %r173;
mad.lo.s32 %r175, %r174, %r66, %r64;
abs.s32 %r176, %r175;
add.s32 %r177, %r302, %r33;
mul.wide.s32 %rd59, %r177, 4;
add.s64 %rd60, %rd2, %rd59;
setp.lt.s32	%p33, %r176, %r63;
selp.b32	%r178, %r176, 0, %p33;
st.global.u32 [%rd60], %r178;
add.s32 %r302, %r302, 1;

BB3_42:
setp.lt.u32	%p34, %r62, 4;
@%p34 bra BB3_45;

mad.lo.s32 %r180, %r62, %r4, %r302;
mul.wide.s32 %rd61, %r180, 4;
add.s64 %rd85, %rd2, %rd61;
shl.b32 %r305, %r302, 1;

BB3_44:
ld.global.f64 %fd268, [%rd5];
cvt.rzi.s32.f64	%r181, %fd268;
cvt.rn.f64.s32	%fd269, %r181;
mul.wide.s32 %rd62, %r305, 4;
add.s64 %rd63, %rd1, %rd62;
ld.global.u32 %r182, [%rd63+4];
cvt.rn.f64.s32	%fd270, %r182;
add.f64 %fd271, %fd269, %fd270;
cvt.rzi.s32.f64	%r183, %fd271;
ld.global.f64 %fd272, [%rd6];
cvt.rzi.s32.f64	%r184, %fd272;
cvt.rn.f64.s32	%fd273, %r184;
ld.global.u32 %r185, [%rd63];
cvt.rn.f64.s32	%fd274, %r185;
add.f64 %fd275, %fd273, %fd274;
cvt.rzi.s32.f64	%r186, %fd275;
mad.lo.s32 %r187, %r183, %r65, %r186;
mad.lo.s32 %r188, %r187, %r66, %r64;
abs.s32 %r189, %r188;
setp.lt.s32	%p35, %r189, %r63;
selp.b32	%r190, %r189, 0, %p35;
st.global.u32 [%rd85], %r190;
ld.global.f64 %fd276, [%rd5];
cvt.rzi.s32.f64	%r191, %fd276;
cvt.rn.f64.s32	%fd277, %r191;
ld.global.u32 %r192, [%rd63+12];
cvt.rn.f64.s32	%fd278, %r192;
add.f64 %fd279, %fd277, %fd278;
cvt.rzi.s32.f64	%r193, %fd279;
ld.global.f64 %fd280, [%rd6];
cvt.rzi.s32.f64	%r194, %fd280;
cvt.rn.f64.s32	%fd281, %r194;
ld.global.u32 %r195, [%rd63+8];
cvt.rn.f64.s32	%fd282, %r195;
add.f64 %fd283, %fd281, %fd282;
cvt.rzi.s32.f64	%r196, %fd283;
mad.lo.s32 %r197, %r193, %r65, %r196;
mad.lo.s32 %r198, %r197, %r66, %r64;
abs.s32 %r199, %r198;
setp.lt.s32	%p36, %r199, %r63;
selp.b32	%r200, %r199, 0, %p36;
st.global.u32 [%rd85+4], %r200;
ld.global.f64 %fd284, [%rd5];
cvt.rzi.s32.f64	%r201, %fd284;
cvt.rn.f64.s32	%fd285, %r201;
ld.global.u32 %r202, [%rd63+20];
cvt.rn.f64.s32	%fd286, %r202;
add.f64 %fd287, %fd285, %fd286;
cvt.rzi.s32.f64	%r203, %fd287;
ld.global.f64 %fd288, [%rd6];
cvt.rzi.s32.f64	%r204, %fd288;
cvt.rn.f64.s32	%fd289, %r204;
ld.global.u32 %r205, [%rd63+16];
cvt.rn.f64.s32	%fd290, %r205;
add.f64 %fd291, %fd289, %fd290;
cvt.rzi.s32.f64	%r206, %fd291;
mad.lo.s32 %r207, %r203, %r65, %r206;
mad.lo.s32 %r208, %r207, %r66, %r64;
abs.s32 %r209, %r208;
setp.lt.s32	%p37, %r209, %r63;
selp.b32	%r210, %r209, 0, %p37;
st.global.u32 [%rd85+8], %r210;
ld.global.f64 %fd292, [%rd5];
cvt.rzi.s32.f64	%r211, %fd292;
cvt.rn.f64.s32	%fd293, %r211;
ld.global.u32 %r212, [%rd63+28];
cvt.rn.f64.s32	%fd294, %r212;
add.f64 %fd295, %fd293, %fd294;
cvt.rzi.s32.f64	%r213, %fd295;
ld.global.f64 %fd296, [%rd6];
cvt.rzi.s32.f64	%r214, %fd296;
cvt.rn.f64.s32	%fd297, %r214;
ld.global.u32 %r215, [%rd63+24];
cvt.rn.f64.s32	%fd298, %r215;
add.f64 %fd299, %fd297, %fd298;
cvt.rzi.s32.f64	%r216, %fd299;
mad.lo.s32 %r217, %r213, %r65, %r216;
mad.lo.s32 %r218, %r217, %r66, %r64;
abs.s32 %r219, %r218;
setp.lt.s32	%p38, %r219, %r63;
selp.b32	%r220, %r219, 0, %p38;
st.global.u32 [%rd85+12], %r220;
add.s64 %rd85, %rd85, 16;
add.s32 %r305, %r305, 8;
add.s32 %r302, %r302, 4;
setp.lt.s32	%p39, %r302, %r62;
@%p39 bra BB3_44;

BB3_45:
@%p27 bra BB3_82;

ld.param.u64 %rd80, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_8];
cvta.to.global.u64 %rd12, %rd80;
mov.f64 %fd302, 0d4000000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r44}, %fd302;
}
bfe.u32 %r222, %r44, 20, 11;
add.s32 %r223, %r222, -1012;
mov.u64 %rd64, 4611686018427387904;
shl.b64 %rd13, %rd64, %r223;
setp.ne.s64	%p2, %rd13, -9223372036854775808;
and.b32 %r45, %r44, 2147483647;
shr.s32 %r224, %r44, 31;
and.b32 %r225, %r224, -2146435072;
add.s32 %r46, %r225, 2146435072;
or.b32 %r47, %r46, -2147483648;
mul.lo.s32 %r227, %r62, %r4;
mul.wide.s32 %rd65, %r227, 4;
add.s64 %rd86, %rd2, %rd65;
mov.f64 %fd379, 0d0000000000000000;
mov.u32 %r307, 0;
bra.uni BB3_47;

BB3_59:
and.b32 %r239, %r50, 2147483647;
setp.ne.s32	%p51, %r239, 2146435072;
@%p51 bra BB3_60;

{
.reg .b32 %temp; 
mov.b64 {%r240, %temp}, %fd48;
}
setp.ne.s32	%p52, %r240, 0;
mov.f64 %fd375, %fd374;
@%p52 bra BB3_64;

setp.eq.s32	%p53, %r45, 1071644672;
or.pred %p54, %p3, %p53;
selp.b32	%r241, %r46, %r47, %p54;
mov.u32 %r242, 0;
mov.b64 %fd375, {%r242, %r241};
bra.uni BB3_64;

BB3_76:
and.b32 %r258, %r52, 2147483647;
setp.ne.s32	%p69, %r258, 2146435072;
@%p69 bra BB3_77;

{
.reg .b32 %temp; 
mov.b64 {%r259, %temp}, %fd60;
}
setp.ne.s32	%p70, %r259, 0;
mov.f64 %fd378, %fd377;
@%p70 bra BB3_81;

setp.eq.s32	%p71, %r45, 1071644672;
or.pred %p72, %p4, %p71;
selp.b32	%r260, %r46, %r47, %p72;
mov.u32 %r261, 0;
mov.b64 %fd378, {%r261, %r260};
bra.uni BB3_81;

BB3_60:
mov.f64 %fd375, %fd374;
bra.uni BB3_64;

BB3_77:
mov.f64 %fd378, %fd377;
bra.uni BB3_81;

BB3_47:
ld.global.s32 %rd66, [%rd86];
add.s64 %rd67, %rd12, %rd66;
ld.global.u8 %r49, [%rd67];
add.s32 %r228, %r49, -100;
cvt.rn.f64.s32	%fd48, %r228;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r50}, %fd48;
}
abs.f64 %fd49, %fd48;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd49;
.param .b64 retval0;
call.uni (retval0), 
__internal_accurate_pow, 
(
param0
);
ld.param.f64	%fd374, [retval0+0];


	}
	setp.gt.s32	%p41, %r50, -1;
or.pred %p3, %p41, %p2;
@%p3 bra BB3_49;

{
.reg .b32 %temp; 
mov.b64 {%temp, %r229}, %fd374;
}
xor.b32 %r230, %r229, -2147483648;
{
.reg .b32 %temp; 
mov.b64 {%r231, %temp}, %fd374;
}
mov.b64 %fd374, {%r231, %r230};

BB3_49:
setp.eq.s32	%p42, %r49, 100;
@%p42 bra BB3_53;
bra.uni BB3_50;

BB3_53:
setp.lt.s32	%p45, %r44, 0;
mov.u32 %r232, 0;
setp.eq.s64	%p46, %rd13, -9223372036854775808;
selp.b32	%r233, %r50, 0, %p46;
or.b32 %r234, %r233, 2146435072;
selp.b32	%r235, %r234, %r233, %p45;
mov.b64 %fd374, {%r232, %r235};
bra.uni BB3_54;

BB3_50:
@%p41 bra BB3_54;

cvt.rzi.f64.f64	%fd304, %fd302;
setp.eq.f64	%p44, %fd304, 0d4000000000000000;
@%p44 bra BB3_54;

mov.f64 %fd374, 0dFFF8000000000000;

BB3_54:
add.f64 %fd375, %fd48, 0d4000000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r236}, %fd375;
}
and.b32 %r237, %r236, 2146435072;
setp.ne.s32	%p47, %r237, 2146435072;
@%p47 bra BB3_55;

setp.gtu.f64	%p48, %fd49, 0d7FF0000000000000;
@%p48 bra BB3_64;

setp.ne.s32	%p49, %r45, 2146435072;
@%p49 bra BB3_59;

{
.reg .b32 %temp; 
mov.b64 {%r238, %temp}, %fd302;
}
setp.eq.s32	%p50, %r238, 0;
@%p50 bra BB3_63;
bra.uni BB3_59;

BB3_63:
setp.lt.s32	%p55, %r44, 0;
mov.u32 %r243, 0;
setp.gt.f64	%p56, %fd49, 0d3FF0000000000000;
selp.b32	%r244, 2146435072, 0, %p56;
xor.b32 %r245, %r244, 2146435072;
selp.b32	%r246, %r245, %r244, %p55;
setp.eq.s32	%p57, %r49, 99;
selp.b32	%r247, 1072693248, %r246, %p57;
mov.b64 %fd375, {%r243, %r247};
bra.uni BB3_64;

BB3_55:
mov.f64 %fd375, %fd374;

BB3_64:
setp.eq.s32	%p58, %r49, 101;
selp.f64	%fd59, 0d3FF0000000000000, %fd375, %p58;
add.s32 %r51, %r49, -228;
cvt.rn.f64.s32	%fd60, %r51;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r52}, %fd60;
}
abs.f64 %fd61, %fd60;

	{
.reg .b32 temp_param_reg;

	.param .b64 param0;
st.param.f64	[param0+0], %fd61;
.param .b64 retval0;
call.uni (retval0), 
__internal_accurate_pow, 
(
param0
);
ld.param.f64	%fd377, [retval0+0];


	}
	setp.gt.s32	%p59, %r52, -1;
or.pred %p4, %p59, %p2;
@%p4 bra BB3_66;

{
.reg .b32 %temp; 
mov.b64 {%temp, %r248}, %fd377;
}
xor.b32 %r249, %r248, -2147483648;
{
.reg .b32 %temp; 
mov.b64 {%r250, %temp}, %fd377;
}
mov.b64 %fd377, {%r250, %r249};

BB3_66:
setp.eq.s32	%p60, %r51, 0;
@%p60 bra BB3_70;
bra.uni BB3_67;

BB3_70:
setp.lt.s32	%p63, %r44, 0;
mov.u32 %r251, 0;
setp.eq.s64	%p64, %rd13, -9223372036854775808;
selp.b32	%r252, %r52, 0, %p64;
or.b32 %r253, %r252, 2146435072;
selp.b32	%r254, %r253, %r252, %p63;
mov.b64 %fd377, {%r251, %r254};
bra.uni BB3_71;

BB3_67:
@%p59 bra BB3_71;

cvt.rzi.f64.f64	%fd308, %fd302;
setp.eq.f64	%p62, %fd308, 0d4000000000000000;
@%p62 bra BB3_71;

mov.f64 %fd377, 0dFFF8000000000000;

BB3_71:
add.f64 %fd378, %fd60, 0d4000000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r255}, %fd378;
}
and.b32 %r256, %r255, 2146435072;
setp.ne.s32	%p65, %r256, 2146435072;
@%p65 bra BB3_72;

setp.gtu.f64	%p66, %fd61, 0d7FF0000000000000;
@%p66 bra BB3_81;

setp.ne.s32	%p67, %r45, 2146435072;
@%p67 bra BB3_76;

{
.reg .b32 %temp; 
mov.b64 {%r257, %temp}, %fd302;
}
setp.eq.s32	%p68, %r257, 0;
@%p68 bra BB3_80;
bra.uni BB3_76;

BB3_80:
setp.lt.s32	%p73, %r44, 0;
mov.u32 %r262, 0;
setp.gt.f64	%p74, %fd61, 0d3FF0000000000000;
selp.b32	%r263, 2146435072, 0, %p74;
xor.b32 %r264, %r263, 2146435072;
selp.b32	%r265, %r264, %r263, %p73;
setp.eq.s32	%p75, %r51, -1;
selp.b32	%r266, 1072693248, %r265, %p75;
mov.b64 %fd378, {%r262, %r266};
bra.uni BB3_81;

BB3_72:
mov.f64 %fd378, %fd377;

BB3_81:
setp.eq.s32	%p76, %r51, 1;
selp.f64	%fd311, 0d3FF0000000000000, %fd378, %p76;
sub.f64 %fd312, %fd59, %fd311;
div.rn.f64 %fd313, %fd312, 0d4049000000000000;
add.f64 %fd379, %fd379, %fd313;
add.s64 %rd86, %rd86, 4;
add.s32 %r307, %r307, 1;
setp.lt.s32	%p77, %r307, %r62;
@%p77 bra BB3_47;

BB3_82:
mov.u32 %r291, %tid.x;
mov.u32 %r290, %ctaid.x;
mov.u32 %r289, %ntid.x;
mad.lo.s32 %r288, %r289, %r290, %r291;
mul.wide.s32 %rd79, %r288, 8;
ld.param.u64 %rd76, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_7];
cvta.to.global.u64 %rd68, %rd76;
add.s64 %rd70, %rd68, %rd79;
cvt.rn.f64.s32	%fd314, %r62;
div.rn.f64 %fd73, %fd379, %fd314;
st.global.f64 [%rd70], %fd73;
ld.global.f64 %fd74, [%rd7];
mov.f64 %fd315, 0d4338000000000000;
mov.f64 %fd316, 0d3FF71547652B82FE;
fma.rn.f64 %fd317, %fd73, %fd316, %fd315;
{
.reg .b32 %temp; 
mov.b64 {%r54, %temp}, %fd317;
}
mov.f64 %fd318, 0dC338000000000000;
add.rn.f64 %fd319, %fd317, %fd318;
mov.f64 %fd320, 0dBFE62E42FEFA39EF;
fma.rn.f64 %fd321, %fd319, %fd320, %fd73;
mov.f64 %fd322, 0dBC7ABC9E3B39803F;
fma.rn.f64 %fd323, %fd319, %fd322, %fd321;
mov.f64 %fd324, 0d3E928AF3FCA213EA;
mov.f64 %fd325, 0d3E5ADE1569CE2BDF;
fma.rn.f64 %fd326, %fd325, %fd323, %fd324;
mov.f64 %fd327, 0d3EC71DEE62401315;
fma.rn.f64 %fd328, %fd326, %fd323, %fd327;
mov.f64 %fd329, 0d3EFA01997C89EB71;
fma.rn.f64 %fd330, %fd328, %fd323, %fd329;
mov.f64 %fd331, 0d3F2A01A014761F65;
fma.rn.f64 %fd332, %fd330, %fd323, %fd331;
mov.f64 %fd333, 0d3F56C16C1852B7AF;
fma.rn.f64 %fd334, %fd332, %fd323, %fd333;
mov.f64 %fd335, 0d3F81111111122322;
fma.rn.f64 %fd336, %fd334, %fd323, %fd335;
mov.f64 %fd337, 0d3FA55555555502A1;
fma.rn.f64 %fd338, %fd336, %fd323, %fd337;
mov.f64 %fd339, 0d3FC5555555555511;
fma.rn.f64 %fd340, %fd338, %fd323, %fd339;
mov.f64 %fd341, 0d3FE000000000000B;
fma.rn.f64 %fd342, %fd340, %fd323, %fd341;
mov.f64 %fd343, 0d3FF0000000000000;
fma.rn.f64 %fd344, %fd342, %fd323, %fd343;
fma.rn.f64 %fd345, %fd344, %fd323, %fd343;
{
.reg .b32 %temp; 
mov.b64 {%r55, %temp}, %fd345;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r56}, %fd345;
}
shl.b32 %r267, %r54, 20;
add.s32 %r268, %r56, %r267;
mov.b64 %fd380, {%r55, %r268};
{
.reg .b32 %temp; 
mov.b64 {%temp, %r269}, %fd73;
}
mov.b32 %f4, %r269;
abs.ftz.f32 %f1, %f4;
setp.lt.ftz.f32	%p78, %f1, 0f4086232B;
@%p78 bra BB3_85;

setp.lt.f64	%p79, %fd73, 0d0000000000000000;
add.f64 %fd346, %fd73, 0d7FF0000000000000;
selp.f64	%fd380, 0d0000000000000000, %fd346, %p79;
setp.geu.ftz.f32	%p80, %f1, 0f40874800;
@%p80 bra BB3_85;

shr.u32 %r270, %r54, 31;
add.s32 %r271, %r54, %r270;
shr.s32 %r272, %r271, 1;
shl.b32 %r273, %r272, 20;
add.s32 %r274, %r273, %r56;
mov.b64 %fd347, {%r55, %r274};
sub.s32 %r275, %r54, %r272;
shl.b32 %r276, %r275, 20;
add.s32 %r277, %r276, 1072693248;
mov.u32 %r278, 0;
mov.b64 %fd348, {%r278, %r277};
mul.f64 %fd380, %fd347, %fd348;

BB3_85:
mul.f64 %fd349, %fd74, %fd380;
st.global.f64 [%rd7], %fd349;

BB3_86:
shl.b32 %r279, %r3, 3;
mov.u32 %r280, _ZZ17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S_E6buffer;
add.s32 %r57, %r280, %r279;
mov.u64 %rd71, 0;
st.shared.u64 [%r57], %rd71;
bar.sync 0;
@!%p1 bra BB3_88;
bra.uni BB3_87;

BB3_87:
ld.global.f64 %fd350, [%rd7];
st.shared.f64 [%r57], %fd350;

BB3_88:
bar.sync 0;
mov.u32 %r286, %ntid.x;
shr.u32 %r308, %r286, 1;
setp.eq.s32	%p81, %r308, 0;
@%p81 bra BB3_92;

BB3_89:
setp.ge.u32	%p82, %r3, %r308;
@%p82 bra BB3_91;

add.s32 %r281, %r308, %r3;
shl.b32 %r282, %r281, 3;
add.s32 %r284, %r280, %r282;
ld.shared.f64 %fd351, [%r57];
ld.shared.f64 %fd352, [%r284];
add.f64 %fd353, %fd352, %fd351;
st.shared.f64 [%r57], %fd353;

BB3_91:
bar.sync 0;
shr.u32 %r308, %r308, 1;
setp.ne.s32	%p83, %r308, 0;
@%p83 bra BB3_89;

BB3_92:
setp.ne.s32	%p84, %r3, 0;
@%p84 bra BB3_94;

ld.param.u64 %rd78, [_Z17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S__param_18];
mov.u32 %r287, %ctaid.x;
ld.shared.f64 %fd354, [_ZZ17likelihood_kernelPdS_S_S_S_PiS0_S_PhS_S_iiiiiiS0_S_E6buffer];
cvta.to.global.u64 %rd72, %rd78;
mul.wide.u32 %rd73, %r287, 8;
add.s64 %rd74, %rd72, %rd73;
st.global.f64 [%rd74], %fd354;

BB3_94:
bar.sync 0;
ret;
}

.func (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
.param .b64 __internal_trig_reduction_slowpathd_param_0,
.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
.local .align 8 .b8 __local_depot4[40];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .f64 %fd<5>;
.reg .b64 %rd<86>;


mov.u64 %SPL, __local_depot4;
ld.param.f64 %fd4, [__internal_trig_reduction_slowpathd_param_0];
ld.param.u64 %rd37, [__internal_trig_reduction_slowpathd_param_1];
add.u64 %rd1, %SPL, 0;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r1}, %fd4;
}
and.b32 %r39, %r1, -2147483648;
shr.u32 %r3, %r1, 20;
bfe.u32 %r4, %r1, 20, 11;
setp.eq.s32	%p1, %r4, 2047;
@%p1 bra BB4_13;

add.s32 %r15, %r4, -1024;
shr.u32 %r16, %r15, 6;
mov.u32 %r17, 15;
sub.s32 %r5, %r17, %r16;
mov.u32 %r18, 19;
sub.s32 %r19, %r18, %r16;
mov.u32 %r20, 18;
min.s32 %r6, %r20, %r19;
mov.u64 %rd79, 0;
setp.ge.s32	%p2, %r5, %r6;
mov.u64 %rd78, %rd1;
@%p2 bra BB4_4;

bfe.u32 %r21, %r1, 20, 11;
add.s32 %r22, %r21, -1024;
shr.u32 %r23, %r22, 6;
neg.s32 %r24, %r23;
mul.wide.s32 %rd41, %r24, 8;
mov.u64 %rd42, __cudart_i2opi_d;
add.s64 %rd43, %rd41, %rd42;
add.s64 %rd75, %rd43, 120;
mov.b64 %rd44, %fd4;
shl.b64 %rd45, %rd44, 11;
or.b64 %rd5, %rd45, -9223372036854775808;
mov.u64 %rd79, 0;
mov.u64 %rd78, %rd1;
mov.u64 %rd76, %rd1;
mov.u32 %r38, %r5;

BB4_3:
.pragma "nounroll";
ld.global.u64 %rd46, [%rd75];
{
.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
mov.b64 {%alo,%ahi}, %rd46;
mov.b64 {%blo,%bhi}, %rd5;
mov.b64 {%clo,%chi}, %rd79;
mad.lo.cc.u32 %r0, %alo, %blo, %clo;
madc.hi.cc.u32 %r1, %alo, %blo, %chi;
madc.hi.u32 %r2, %alo, %bhi, 0;
mad.lo.cc.u32 %r1, %alo, %bhi, %r1;
madc.hi.cc.u32 %r2, %ahi, %blo, %r2;
madc.hi.u32 %r3, %ahi, %bhi, 0;
mad.lo.cc.u32 %r1, %ahi, %blo, %r1;
madc.lo.cc.u32 %r2, %ahi, %bhi, %r2;
addc.u32 %r3, %r3, 0;
mov.b64 %rd47, {%r0,%r1};
mov.b64 %rd79, {%r2,%r3};
}
st.local.u64 [%rd76], %rd47;
add.s32 %r38, %r38, 1;
sub.s32 %r25, %r38, %r5;
mul.wide.s32 %rd48, %r25, 8;
add.s64 %rd76, %rd1, %rd48;
add.s64 %rd75, %rd75, 8;
add.s64 %rd78, %rd78, 8;
setp.lt.s32	%p3, %r38, %r6;
@%p3 bra BB4_3;

BB4_4:
st.local.u64 [%rd78], %rd79;
ld.local.u64 %rd81, [%rd1+16];
ld.local.u64 %rd80, [%rd1+24];
and.b32 %r9, %r3, 63;
setp.eq.s32	%p4, %r9, 0;
@%p4 bra BB4_6;

mov.u32 %r26, 64;
sub.s32 %r27, %r26, %r9;
shl.b64 %rd49, %rd80, %r9;
shr.u64 %rd50, %rd81, %r27;
or.b64 %rd80, %rd49, %rd50;
shl.b64 %rd51, %rd81, %r9;
ld.local.u64 %rd52, [%rd1+8];
shr.u64 %rd53, %rd52, %r27;
or.b64 %rd81, %rd53, %rd51;

BB4_6:
shr.u64 %rd54, %rd80, 62;
cvt.u32.u64	%r28, %rd54;
shr.u64 %rd55, %rd81, 62;
shl.b64 %rd56, %rd80, 2;
or.b64 %rd82, %rd55, %rd56;
shl.b64 %rd83, %rd81, 2;
shr.u64 %rd57, %rd80, 61;
cvt.u32.u64	%r29, %rd57;
and.b32 %r30, %r29, 1;
add.s32 %r31, %r30, %r28;
neg.s32 %r32, %r31;
setp.eq.s32	%p5, %r39, 0;
selp.b32	%r33, %r31, %r32, %p5;
cvta.to.local.u64 %rd58, %rd37;
st.local.u32 [%rd58], %r33;
setp.eq.s32	%p6, %r30, 0;
@%p6 bra BB4_8;

mov.u64 %rd59, 0;
{
.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
mov.b64 {%a0,%a1}, %rd59;
mov.b64 {%a2,%a3}, %rd59;
mov.b64 {%b0,%b1}, %rd83;
mov.b64 {%b2,%b3}, %rd82;
sub.cc.u32 %r0, %a0, %b0;
subc.cc.u32 %r1, %a1, %b1;
subc.cc.u32 %r2, %a2, %b2;
subc.u32 %r3, %a3, %b3;
mov.b64 %rd83, {%r0,%r1};
mov.b64 %rd82, {%r2,%r3};
}
xor.b32 %r39, %r39, -2147483648;

BB4_8:
clz.b64 %r40, %rd82;
setp.eq.s32	%p7, %r40, 0;
@%p7 bra BB4_10;

shl.b64 %rd60, %rd82, %r40;
mov.u32 %r34, 64;
sub.s32 %r35, %r34, %r40;
shr.u64 %rd61, %rd83, %r35;
or.b64 %rd82, %rd61, %rd60;

BB4_10:
mov.u64 %rd62, -3958705157555305931;
{
.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
mov.b64 {%alo,%ahi}, %rd82;
mov.b64 {%blo,%bhi}, %rd62;
mul.lo.u32 %r0, %alo, %blo;
mul.hi.u32 %r1, %alo, %blo;
mad.lo.cc.u32 %r1, %alo, %bhi, %r1;
madc.hi.u32 %r2, %alo, %bhi, 0;
mad.lo.cc.u32 %r1, %ahi, %blo, %r1;
madc.hi.cc.u32 %r2, %ahi, %blo, %r2;
madc.hi.u32 %r3, %ahi, %bhi, 0;
mad.lo.cc.u32 %r2, %ahi, %bhi, %r2;
addc.u32 %r3, %r3, 0;
mov.b64 %rd32, {%r0,%r1};
mov.b64 %rd85, {%r2,%r3};
}
setp.lt.s64	%p8, %rd85, 1;
@%p8 bra BB4_12;

{
.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
mov.b64 {%a0,%a1}, %rd32;
mov.b64 {%a2,%a3}, %rd85;
mov.b64 {%b0,%b1}, %rd32;
mov.b64 {%b2,%b3}, %rd85;
add.cc.u32 %r0, %a0, %b0;
addc.cc.u32 %r1, %a1, %b1;
addc.cc.u32 %r2, %a2, %b2;
addc.u32 %r3, %a3, %b3;
mov.b64 %rd63, {%r0,%r1};
mov.b64 %rd85, {%r2,%r3};
}
add.s32 %r40, %r40, 1;

BB4_12:
cvt.u64.u32	%rd64, %r39;
shl.b64 %rd65, %rd64, 32;
mov.u32 %r36, 1022;
sub.s32 %r37, %r36, %r40;
cvt.u64.u32	%rd66, %r37;
shl.b64 %rd67, %rd66, 52;
add.s64 %rd68, %rd85, 1;
shr.u64 %rd69, %rd68, 10;
add.s64 %rd70, %rd69, 1;
shr.u64 %rd71, %rd70, 1;
add.s64 %rd72, %rd67, %rd71;
or.b64 %rd73, %rd72, %rd65;
mov.b64 %fd4, %rd73;

BB4_13:
st.param.f64	[func_retval0+0], %fd4;
ret;
}

.func (.param .b64 func_retval0) __internal_accurate_pow(
.param .b64 __internal_accurate_pow_param_0
)
{
.reg .pred %p<9>;
.reg .f32 %f<3>;
.reg .b32 %r<53>;
.reg .f64 %fd<138>;


ld.param.f64 %fd12, [__internal_accurate_pow_param_0];
{
.reg .b32 %temp; 
mov.b64 {%temp, %r50}, %fd12;
}
{
.reg .b32 %temp; 
mov.b64 {%r49, %temp}, %fd12;
}
shr.u32 %r51, %r50, 20;
setp.ne.s32	%p1, %r51, 0;
@%p1 bra BB5_2;

mul.f64 %fd13, %fd12, 0d4350000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r50}, %fd13;
}
{
.reg .b32 %temp; 
mov.b64 {%r49, %temp}, %fd13;
}
shr.u32 %r16, %r50, 20;
add.s32 %r51, %r16, -54;

BB5_2:
add.s32 %r52, %r51, -1023;
and.b32 %r17, %r50, -2146435073;
or.b32 %r18, %r17, 1072693248;
mov.b64 %fd135, {%r49, %r18};
setp.lt.u32	%p2, %r18, 1073127583;
@%p2 bra BB5_4;

{
.reg .b32 %temp; 
mov.b64 {%r19, %temp}, %fd135;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r20}, %fd135;
}
add.s32 %r21, %r20, -1048576;
mov.b64 %fd135, {%r19, %r21};
add.s32 %r52, %r51, -1022;

BB5_4:
add.f64 %fd14, %fd135, 0d3FF0000000000000;
rcp.approx.ftz.f64 %fd15, %fd14;
neg.f64 %fd16, %fd14;
mov.f64 %fd17, 0d3FF0000000000000;
fma.rn.f64 %fd18, %fd16, %fd15, %fd17;
fma.rn.f64 %fd19, %fd18, %fd18, %fd18;
fma.rn.f64 %fd20, %fd19, %fd15, %fd15;
add.f64 %fd21, %fd135, 0dBFF0000000000000;
mul.f64 %fd22, %fd21, %fd20;
fma.rn.f64 %fd23, %fd21, %fd20, %fd22;
mul.f64 %fd24, %fd23, %fd23;
mov.f64 %fd25, 0d3ED0F5D241AD3B5A;
mov.f64 %fd26, 0d3EB0F5FF7D2CAFE2;
fma.rn.f64 %fd27, %fd26, %fd24, %fd25;
mov.f64 %fd28, 0d3EF3B20A75488A3F;
fma.rn.f64 %fd29, %fd27, %fd24, %fd28;
mov.f64 %fd30, 0d3F1745CDE4FAECD5;
fma.rn.f64 %fd31, %fd29, %fd24, %fd30;
mov.f64 %fd32, 0d3F3C71C7258A578B;
fma.rn.f64 %fd33, %fd31, %fd24, %fd32;
mov.f64 %fd34, 0d3F6249249242B910;
fma.rn.f64 %fd35, %fd33, %fd24, %fd34;
mov.f64 %fd36, 0d3F89999999999DFB;
fma.rn.f64 %fd37, %fd35, %fd24, %fd36;
sub.f64 %fd38, %fd21, %fd23;
add.f64 %fd39, %fd38, %fd38;
neg.f64 %fd40, %fd23;
fma.rn.f64 %fd41, %fd40, %fd21, %fd39;
mul.f64 %fd42, %fd20, %fd41;
fma.rn.f64 %fd43, %fd24, %fd37, 0d3FB5555555555555;
mov.f64 %fd44, 0d3FB5555555555555;
sub.f64 %fd45, %fd44, %fd43;
fma.rn.f64 %fd46, %fd24, %fd37, %fd45;
add.f64 %fd47, %fd46, 0d0000000000000000;
add.f64 %fd48, %fd47, 0dBC46A4CB00B9E7B0;
add.f64 %fd49, %fd43, %fd48;
sub.f64 %fd50, %fd43, %fd49;
add.f64 %fd51, %fd48, %fd50;
mul.rn.f64 %fd52, %fd23, %fd23;
neg.f64 %fd53, %fd52;
fma.rn.f64 %fd54, %fd23, %fd23, %fd53;
{
.reg .b32 %temp; 
mov.b64 {%r22, %temp}, %fd42;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r23}, %fd42;
}
add.s32 %r24, %r23, 1048576;
mov.b64 %fd55, {%r22, %r24};
fma.rn.f64 %fd56, %fd23, %fd55, %fd54;
mul.rn.f64 %fd57, %fd52, %fd23;
neg.f64 %fd58, %fd57;
fma.rn.f64 %fd59, %fd52, %fd23, %fd58;
fma.rn.f64 %fd60, %fd52, %fd42, %fd59;
fma.rn.f64 %fd61, %fd56, %fd23, %fd60;
mul.rn.f64 %fd62, %fd49, %fd57;
neg.f64 %fd63, %fd62;
fma.rn.f64 %fd64, %fd49, %fd57, %fd63;
fma.rn.f64 %fd65, %fd49, %fd61, %fd64;
fma.rn.f64 %fd66, %fd51, %fd57, %fd65;
add.f64 %fd67, %fd62, %fd66;
sub.f64 %fd68, %fd62, %fd67;
add.f64 %fd69, %fd66, %fd68;
add.f64 %fd70, %fd23, %fd67;
sub.f64 %fd71, %fd23, %fd70;
add.f64 %fd72, %fd67, %fd71;
add.f64 %fd73, %fd69, %fd72;
add.f64 %fd74, %fd42, %fd73;
add.f64 %fd75, %fd70, %fd74;
sub.f64 %fd76, %fd70, %fd75;
add.f64 %fd77, %fd74, %fd76;
xor.b32 %r25, %r52, -2147483648;
mov.u32 %r26, -2147483648;
mov.u32 %r27, 1127219200;
mov.b64 %fd78, {%r25, %r27};
mov.b64 %fd79, {%r26, %r27};
sub.f64 %fd80, %fd78, %fd79;
mov.f64 %fd81, 0d3FE62E42FEFA39EF;
fma.rn.f64 %fd82, %fd80, %fd81, %fd75;
neg.f64 %fd83, %fd80;
fma.rn.f64 %fd84, %fd83, %fd81, %fd82;
sub.f64 %fd85, %fd84, %fd75;
sub.f64 %fd86, %fd77, %fd85;
mov.f64 %fd87, 0d3C7ABC9E3B39803F;
fma.rn.f64 %fd88, %fd80, %fd87, %fd86;
add.f64 %fd89, %fd82, %fd88;
sub.f64 %fd90, %fd82, %fd89;
add.f64 %fd91, %fd88, %fd90;
mov.f64 %fd92, 0d4000000000000000;
{
.reg .b32 %temp; 
mov.b64 {%temp, %r28}, %fd92;
}
add.s32 %r29, %r28, %r28;
setp.gt.u32	%p3, %r29, -33554433;
and.b32 %r30, %r28, -15728641;
selp.b32	%r31, %r30, %r28, %p3;
{
.reg .b32 %temp; 
mov.b64 {%r32, %temp}, %fd92;
}
mov.b64 %fd93, {%r32, %r31};
mul.rn.f64 %fd94, %fd89, %fd93;
neg.f64 %fd95, %fd94;
fma.rn.f64 %fd96, %fd89, %fd93, %fd95;
fma.rn.f64 %fd97, %fd91, %fd93, %fd96;
add.f64 %fd4, %fd94, %fd97;
sub.f64 %fd98, %fd94, %fd4;
add.f64 %fd5, %fd97, %fd98;
mov.f64 %fd99, 0d4338000000000000;
mov.f64 %fd100, 0d3FF71547652B82FE;
fma.rn.f64 %fd101, %fd4, %fd100, %fd99;
{
.reg .b32 %temp; 
mov.b64 {%r13, %temp}, %fd101;
}
mov.f64 %fd102, 0dC338000000000000;
add.rn.f64 %fd103, %fd101, %fd102;
mov.f64 %fd104, 0dBFE62E42FEFA39EF;
fma.rn.f64 %fd105, %fd103, %fd104, %fd4;
mov.f64 %fd106, 0dBC7ABC9E3B39803F;
fma.rn.f64 %fd107, %fd103, %fd106, %fd105;
mov.f64 %fd108, 0d3E928AF3FCA213EA;
mov.f64 %fd109, 0d3E5ADE1569CE2BDF;
fma.rn.f64 %fd110, %fd109, %fd107, %fd108;
mov.f64 %fd111, 0d3EC71DEE62401315;
fma.rn.f64 %fd112, %fd110, %fd107, %fd111;
mov.f64 %fd113, 0d3EFA01997C89EB71;
fma.rn.f64 %fd114, %fd112, %fd107, %fd113;
mov.f64 %fd115, 0d3F2A01A014761F65;
fma.rn.f64 %fd116, %fd114, %fd107, %fd115;
mov.f64 %fd117, 0d3F56C16C1852B7AF;
fma.rn.f64 %fd118, %fd116, %fd107, %fd117;
mov.f64 %fd119, 0d3F81111111122322;
fma.rn.f64 %fd120, %fd118, %fd107, %fd119;
mov.f64 %fd121, 0d3FA55555555502A1;
fma.rn.f64 %fd122, %fd120, %fd107, %fd121;
mov.f64 %fd123, 0d3FC5555555555511;
fma.rn.f64 %fd124, %fd122, %fd107, %fd123;
mov.f64 %fd125, 0d3FE000000000000B;
fma.rn.f64 %fd126, %fd124, %fd107, %fd125;
fma.rn.f64 %fd127, %fd126, %fd107, %fd17;
fma.rn.f64 %fd128, %fd127, %fd107, %fd17;
{
.reg .b32 %temp; 
mov.b64 {%r14, %temp}, %fd128;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r15}, %fd128;
}
shl.b32 %r33, %r13, 20;
add.s32 %r34, %r15, %r33;
mov.b64 %fd136, {%r14, %r34};
{
.reg .b32 %temp; 
mov.b64 {%temp, %r35}, %fd4;
}
mov.b32 %f2, %r35;
abs.ftz.f32 %f1, %f2;
setp.lt.ftz.f32	%p4, %f1, 0f4086232B;
@%p4 bra BB5_7;

setp.lt.f64	%p5, %fd4, 0d0000000000000000;
add.f64 %fd129, %fd4, 0d7FF0000000000000;
selp.f64	%fd136, 0d0000000000000000, %fd129, %p5;
setp.geu.ftz.f32	%p6, %f1, 0f40874800;
@%p6 bra BB5_7;

mov.f64 %fd134, 0d4338000000000000;
mov.f64 %fd133, 0d3FF71547652B82FE;
fma.rn.f64 %fd132, %fd4, %fd133, %fd134;
{
.reg .b32 %temp; 
mov.b64 {%r48, %temp}, %fd132;
}
shr.u32 %r36, %r48, 31;
add.s32 %r37, %r48, %r36;
shr.s32 %r38, %r37, 1;
shl.b32 %r39, %r38, 20;
add.s32 %r40, %r39, %r15;
mov.b64 %fd130, {%r14, %r40};
sub.s32 %r41, %r48, %r38;
shl.b32 %r42, %r41, 20;
add.s32 %r43, %r42, 1072693248;
mov.u32 %r44, 0;
mov.b64 %fd131, {%r44, %r43};
mul.f64 %fd136, %fd130, %fd131;

BB5_7:
{
.reg .b32 %temp; 
mov.b64 {%temp, %r45}, %fd136;
}
and.b32 %r46, %r45, 2147483647;
setp.ne.s32	%p7, %r46, 2146435072;
@%p7 bra BB5_9;

{
.reg .b32 %temp; 
mov.b64 {%r47, %temp}, %fd136;
}
setp.eq.s32	%p8, %r47, 0;
@%p8 bra BB5_10;

BB5_9:
fma.rn.f64 %fd136, %fd136, %fd5, %fd136;

BB5_10:
st.param.f64	[func_retval0+0], %fd136;
ret;
}


